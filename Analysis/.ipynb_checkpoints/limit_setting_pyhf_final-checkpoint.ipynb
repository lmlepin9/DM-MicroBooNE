{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ff150e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uproot as u\n",
    "import numpy as np\n",
    "import pyhf\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c333d47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test option\n",
    "tests = False\n",
    "\n",
    "flat_uncertainty=False\n",
    "uncertainty = 0.5\n",
    "nominal_eps = 1e-3 \n",
    "obs_eps = []\n",
    "\n",
    "# Corrections for time window and flux uncertainty\n",
    "\n",
    "fraction_outside = 1.1 \n",
    "flux_uncert = 0.22 \n",
    "\n",
    "# Array to contain expected values \n",
    "obs_eps = []\n",
    "exp_eps = []\n",
    "exp_minus_two = []\n",
    "exp_minus_one = []\n",
    "exp_plus_one = []\n",
    "exp_plus_two = []\n",
    "CLb_values = []\n",
    "\n",
    "scaling_list = [] \n",
    "dm_type = \"fermion\"\n",
    "alpha = 0.1\n",
    "ratio = \"0.6\"\n",
    "tag = \"CNN\"\n",
    "\n",
    "\n",
    "if(alpha==1.0):\n",
    "    scaling = 0.05\n",
    "else:\n",
    "    scaling = 0.05\n",
    "\n",
    "\n",
    "base_dir_run1 = \"/home/lmlepin/Desktop/dm_sets/dark_tridents_analysis/run1_samples/\"\n",
    "base_dir_run3 = \"/home/lmlepin/Desktop/dm_sets/dark_tridents_analysis/run3_samples/\"\n",
    "\n",
    "signal_dir_run1 = \"/home/lmlepin/Desktop/dm_sets/dark_tridents_analysis/run1_signal/\"\n",
    "signal_dir_run3 = \"/home/lmlepin/Desktop/dm_sets/dark_tridents_analysis/run3_signal/\"\n",
    "\n",
    "\n",
    "signal_run1 = u.open(signal_dir_run1 + dm_type + \"_ratio_\" + ratio + \"_signal_hist_run1_\" + tag + \".root\")\n",
    "signal_run3 = u.open(signal_dir_run3 + dm_type + \"_ratio_\" + ratio + \"_signal_hist_run3_\" + tag + \".root\")\n",
    "\n",
    "bkg_run1 = u.open(base_dir_run1 + \"background_hist_run1_\" + tag + \".root\")\n",
    "bkg_run3 = u.open(base_dir_run3 + \"background_hist_run3_\" + tag + \".root\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "337cd29b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Background events run1: 222.15\n",
      "Background events run3: 447.76\n",
      "\n",
      "\n",
      "Data events run1: 226.00\n",
      "Data events run3: 383.00\n"
     ]
    }
   ],
   "source": [
    "if(ratio == \"0.6\"):\n",
    "    #masses = [\"0.01\", \"0.02\", \"0.03\", \"0.04\", \"0.05\", \"0.06\", \"0.07\", \"0.08\", \"0.09\", \"0.1\", \"0.2\", \"0.3\", \"0.4\"]\n",
    "    masses = [\"0.05\"]\n",
    "else:\n",
    "    masses = [\"0.010\", \"0.020\", \"0.030\", \n",
    "              \"0.040\", \"0.050\", \"0.060\", \n",
    "              \"0.065\", \"0.070\", \"0.075\", \n",
    "              \"0.080\", \"0.085\", \"0.090\", \n",
    "              \"0.095\", \"0.100\", \"0.105\", \n",
    "              \"0.110\", \"0.115\", \"0.120\", \"0.125\"]\n",
    "    \n",
    "print(\"Background events run1: {nevts:.2f}\".format( nevts= np.sum(bkg_run1[\"bkg_total_hist\"].values())))\n",
    "print(\"Background events run3: {nevts:.2f}\".format( nevts= np.sum(bkg_run3[\"bkg_total_hist\"].values()))) \n",
    "print(\"\\n\")\n",
    "print(\"Data events run1: {nevts:.2f}\".format( nevts= np.sum(bkg_run1[\"data_hist\"].values())))\n",
    "print(\"Data events run3: {nevts:.2f}\".format( nevts= np.sum(bkg_run3[\"data_hist\"].values()))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1adda34d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing mass: 0.01\n",
      "Signal events run1: 298455.00399\n",
      "Signal events run3: 763695.11822\n",
      "Scaling factor:  3.326593693628743e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lmlepin/anaconda3/envs/dark_trident/lib/python3.7/site-packages/pyhf/infer/calculators.py:369: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  teststat = (qmu - qmu_A) / (2 * self.sqrtqmuA_v)\n",
      "/home/lmlepin/anaconda3/envs/dark_trident/lib/python3.7/site-packages/pyhf/infer/calculators.py:417: RuntimeWarning: invalid value encountered in true_divide\n",
      "  CLs = tensorlib.astensor(CLsb / CLb)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_44372/3399248524.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0mpoi_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m         obs_limit, exp_limits, (scan, results) = pyhf.infer.intervals.upperlimit(\n\u001b[0;32m--> 103\u001b[0;31m             obs, model, poi_values, level=0.1, return_results=True)\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dark_trident/lib/python3.7/site-packages/pyhf/infer/intervals.py\u001b[0m in \u001b[0;36mupperlimit\u001b[0;34m(data, model, scan, level, return_results)\u001b[0m\n\u001b[1;32m     58\u001b[0m     results = [\n\u001b[1;32m     59\u001b[0m         \u001b[0mhypotest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_stat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"qtilde\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_expected_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mmu\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mscan\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m     ]\n\u001b[1;32m     62\u001b[0m     \u001b[0mobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dark_trident/lib/python3.7/site-packages/pyhf/infer/intervals.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     58\u001b[0m     results = [\n\u001b[1;32m     59\u001b[0m         \u001b[0mhypotest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_stat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"qtilde\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_expected_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mmu\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mscan\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m     ]\n\u001b[1;32m     62\u001b[0m     \u001b[0mobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dark_trident/lib/python3.7/site-packages/pyhf/infer/__init__.py\u001b[0m in \u001b[0;36mhypotest\u001b[0;34m(poi_test, data, pdf, init_pars, par_bounds, fixed_params, calctype, return_tail_probs, return_expected, return_expected_set, **kwargs)\u001b[0m\n\u001b[1;32m    157\u001b[0m     )\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m     \u001b[0mteststat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mteststatistic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoi_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m     \u001b[0msig_plus_bkg_distribution\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbkg_only_distribution\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoi_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dark_trident/lib/python3.7/site-packages/pyhf/infer/calculators.py\u001b[0m in \u001b[0;36mteststatistic\u001b[0;34m(self, poi_test)\u001b[0m\n\u001b[1;32m    332\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_pars\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpar_bounds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfixed_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m         )\n\u001b[1;32m    336\u001b[0m         \u001b[0msqrtqmu_v\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensorlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqmu_v\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dark_trident/lib/python3.7/site-packages/pyhf/infer/test_statistics.py\u001b[0m in \u001b[0;36mqmu_tilde\u001b[0;34m(mu, data, pdf, init_pars, par_bounds, fixed_params)\u001b[0m\n\u001b[1;32m    187\u001b[0m             \u001b[0;34m+\u001b[0m \u001b[0;34m'Use the qmu test statistic (pyhf.infer.test_statistics.qmu) instead.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m         )\n\u001b[0;32m--> 189\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_qmu_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_pars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpar_bounds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfixed_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dark_trident/lib/python3.7/site-packages/pyhf/infer/test_statistics.py\u001b[0m in \u001b[0;36m_qmu_like\u001b[0;34m(mu, data, pdf, init_pars, par_bounds, fixed_params)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mtensorlib\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     tmu_like_stat, (_, muhatbhat) = _tmu_like(\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_pars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpar_bounds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfixed_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_fitted_pars\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     )\n\u001b[1;32m     28\u001b[0m     qmu_like_stat = tensorlib.where(\n",
      "\u001b[0;32m~/anaconda3/envs/dark_trident/lib/python3.7/site-packages/pyhf/infer/test_statistics.py\u001b[0m in \u001b[0;36m_tmu_like\u001b[0;34m(mu, data, pdf, init_pars, par_bounds, fixed_params, return_fitted_pars)\u001b[0m\n\u001b[1;32m     46\u001b[0m     )\n\u001b[1;32m     47\u001b[0m     muhatbhat, unconstrained_fit_lhood_val = fit(\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_pars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpar_bounds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfixed_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_fitted_val\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m     )\n\u001b[1;32m     50\u001b[0m     \u001b[0mlog_likelihood_ratio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfixed_poi_fit_lhood_val\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0munconstrained_fit_lhood_val\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dark_trident/lib/python3.7/site-packages/pyhf/infer/mle.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(data, pdf, init_pars, par_bounds, fixed_params, **kwargs)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m     return opt.minimize(\n\u001b[0;32m--> 132\u001b[0;31m         \u001b[0mtwice_nll\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_pars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpar_bounds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfixed_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m     )\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dark_trident/lib/python3.7/site-packages/pyhf/optimize/mixins.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(self, objective, data, pdf, init_pars, par_bounds, fixed_vals, return_fitted_val, return_result_obj, return_uncertainties, return_correlations, do_grad, do_stitch, **kwargs)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         result = self._internal_minimize(\n\u001b[0;32m--> 185\u001b[0;31m             \u001b[0;34m**\u001b[0m\u001b[0mminimizer_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpar_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpar_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m         )\n\u001b[1;32m    187\u001b[0m         result = self._internal_postprocess(\n",
      "\u001b[0;32m~/anaconda3/envs/dark_trident/lib/python3.7/site-packages/pyhf/optimize/mixins.py\u001b[0m in \u001b[0;36m_internal_minimize\u001b[0;34m(self, func, x0, do_grad, bounds, fixed_vals, options, par_names)\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0mbounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbounds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0mfixed_vals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfixed_vals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m             \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m         )\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dark_trident/lib/python3.7/site-packages/pyhf/optimize/opt_scipy.py\u001b[0m in \u001b[0;36m_minimize\u001b[0;34m(self, minimizer, func, x0, do_grad, bounds, fixed_vals, options)\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0mconstraints\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconstraints\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m             \u001b[0mtol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m             \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaxiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmaxiter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msolver_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m         )\n",
      "\u001b[0;32m~/anaconda3/envs/dark_trident/lib/python3.7/site-packages/scipy/optimize/_minimize.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    630\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'slsqp'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m         return _minimize_slsqp(fun, x0, args, jac, bounds,\n\u001b[0;32m--> 632\u001b[0;31m                                constraints, callback=callback, **options)\n\u001b[0m\u001b[1;32m    633\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'trust-constr'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m         return _minimize_trustregion_constr(fun, x0, args, jac, hess, hessp,\n",
      "\u001b[0;32m~/anaconda3/envs/dark_trident/lib/python3.7/site-packages/scipy/optimize/slsqp.py\u001b[0m in \u001b[0;36m_minimize_slsqp\u001b[0;34m(func, x0, args, jac, bounds, constraints, maxiter, ftol, iprint, disp, eps, callback, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# gradient evaluation required\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 437\u001b[0;31m             \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    438\u001b[0m             \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_eval_con_normals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcons\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mla\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmieq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dark_trident/lib/python3.7/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36meval\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    273\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_clip_x\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbounds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dark_trident/lib/python3.7/site-packages/scipy/optimize/_differentiable_functions.py\u001b[0m in \u001b[0;36mgrad\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray_equal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_x_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dark_trident/lib/python3.7/site-packages/scipy/optimize/_differentiable_functions.py\u001b[0m in \u001b[0;36m_update_grad\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    236\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_update_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg_updated\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_grad_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg_updated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dark_trident/lib/python3.7/site-packages/scipy/optimize/_differentiable_functions.py\u001b[0m in \u001b[0;36mupdate_grad\u001b[0;34m()\u001b[0m\n\u001b[1;32m    154\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mngev\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m                 self.g = approx_derivative(fun_wrapped, self.x, f0=self.f,\n\u001b[0;32m--> 156\u001b[0;31m                                            **finite_diff_options)\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_grad_impl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupdate_grad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dark_trident/lib/python3.7/site-packages/scipy/optimize/_numdiff.py\u001b[0m in \u001b[0;36mapprox_derivative\u001b[0;34m(fun, x0, method, rel_step, abs_step, f0, bounds, sparsity, as_linear_operator, args, kwargs)\u001b[0m\n\u001b[1;32m    485\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msparsity\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m             return _dense_difference(fun_wrapped, x0, f0, h,\n\u001b[0;32m--> 487\u001b[0;31m                                      use_one_sided, method)\n\u001b[0m\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msparsity\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msparsity\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dark_trident/lib/python3.7/site-packages/scipy/optimize/_numdiff.py\u001b[0m in \u001b[0;36m_dense_difference\u001b[0;34m(fun, x0, f0, h, use_one_sided, method)\u001b[0m\n\u001b[1;32m    555\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx0\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mh_vecs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m             \u001b[0mdx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mx0\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Recompute dx as exactly representable number.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 557\u001b[0;31m             \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mf0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    558\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'3-point'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0muse_one_sided\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[0mx1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx0\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mh_vecs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dark_trident/lib/python3.7/site-packages/scipy/optimize/_numdiff.py\u001b[0m in \u001b[0;36mfun_wrapped\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfun_wrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 437\u001b[0;31m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0matleast_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    438\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m             raise RuntimeError(\"`fun` return value has \"\n",
      "\u001b[0;32m~/anaconda3/envs/dark_trident/lib/python3.7/site-packages/scipy/optimize/_differentiable_functions.py\u001b[0m in \u001b[0;36mfun_wrapped\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    132\u001b[0m             \u001b[0;31m# Overwriting results in undefined behaviour because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m             \u001b[0;31m# fun(self.x) will change self.x, with the two no longer linked.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dark_trident/lib/python3.7/site-packages/pyhf/optimize/opt_numpy.py\u001b[0m in \u001b[0;36mfunc\u001b[0;34m(pars)\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mpars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensorlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mconstrained_pars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstitch_pars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobjective\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconstrained_pars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dark_trident/lib/python3.7/site-packages/pyhf/infer/mle.py\u001b[0m in \u001b[0;36mtwice_nll\u001b[0;34m(pars, data, pdf)\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTwo\u001b[0m \u001b[0mtimes\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mnegative\u001b[0m \u001b[0mlog\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlikelihood\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0mln\u001b[0m \u001b[0mL\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0mboldsymbol\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \"\"\"\n\u001b[0;32m---> 53\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mpdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogpdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dark_trident/lib/python3.7/site-packages/pyhf/pdf.py\u001b[0m in \u001b[0;36mlogpdf\u001b[0;34m(self, pars, data)\u001b[0m\n\u001b[1;32m    851\u001b[0m                 )\n\u001b[1;32m    852\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 853\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_pdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    854\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m             if (\n",
      "\u001b[0;32m~/anaconda3/envs/dark_trident/lib/python3.7/site-packages/pyhf/probability.py\u001b[0m in \u001b[0;36mlog_prob\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    286\u001b[0m         \"\"\"\n\u001b[1;32m    287\u001b[0m         \u001b[0mconstituent_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m         \u001b[0mpdfvals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconstituent_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    289\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mSimultaneous\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_joint_logpdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpdfvals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dark_trident/lib/python3.7/site-packages/pyhf/probability.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    286\u001b[0m         \"\"\"\n\u001b[1;32m    287\u001b[0m         \u001b[0mconstituent_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m         \u001b[0mpdfvals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconstituent_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    289\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mSimultaneous\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_joint_logpdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpdfvals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dark_trident/lib/python3.7/site-packages/pyhf/probability.py\u001b[0m in \u001b[0;36mlog_prob\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    286\u001b[0m         \"\"\"\n\u001b[1;32m    287\u001b[0m         \u001b[0mconstituent_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m         \u001b[0mpdfvals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconstituent_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    289\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mSimultaneous\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_joint_logpdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpdfvals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dark_trident/lib/python3.7/site-packages/pyhf/probability.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    286\u001b[0m         \"\"\"\n\u001b[1;32m    287\u001b[0m         \u001b[0mconstituent_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m         \u001b[0mpdfvals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconstituent_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    289\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mSimultaneous\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_joint_logpdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpdfvals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dark_trident/lib/python3.7/site-packages/pyhf/probability.py\u001b[0m in \u001b[0;36mlog_prob\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0mtensorlib\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensorlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dark_trident/lib/python3.7/site-packages/pyhf/tensor/numpy_backend.py\u001b[0m in \u001b[0;36msum\u001b[0;34m(self, tensor_in, axis)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mproduct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36msum\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dark_trident/lib/python3.7/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36msum\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2259\u001b[0m     return _wrapreduction(a, np.add, 'sum', axis, dtype, out, keepdims=keepdims,\n\u001b[0;32m-> 2260\u001b[0;31m                           initial=initial, where=where)\n\u001b[0m\u001b[1;32m   2261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dark_trident/lib/python3.7/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     84\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if(not tests):\n",
    "\n",
    "\n",
    "    delimiter=0\n",
    "    pot_uncert = 0.02 # 2% POT uncertainty \n",
    "\n",
    "\n",
    "    total_bkg = np.sum(bkg_run1[\"bkg_total_hist\"].values()) + np.sum(bkg_run3[\"bkg_total_hist\"].values())\n",
    "\n",
    "    total_run1 = np.sum(bkg_run1[\"bkg_total_hist\"].values())\n",
    "    total_run3 = np.sum(bkg_run3[\"bkg_total_hist\"].values())\n",
    "\n",
    "    n_back = bkg_run1[\"bkg_total_hist\"].values().tolist()[delimiter:]\n",
    "    n_back.extend(bkg_run3[\"bkg_total_hist\"].values().tolist()[delimiter:])\n",
    "\n",
    "\n",
    "    n_data = bkg_run1[\"data_hist\"].values().tolist()[delimiter:]\n",
    "    n_data.extend(bkg_run3[\"data_hist\"].values().tolist()[delimiter:])\n",
    "\n",
    "\n",
    "    if(flat_uncertainty):\n",
    "        back_sigma =  (bkg_run1[\"bkg_total_hist\"].values()*uncertainty).tolist()\n",
    "        back_sigma.extend((bkg_run3[\"bkg_total_hist\"].values()*uncertainty).tolist())\n",
    "    else:\n",
    "        back_sigma =  (bkg_run1[\"bkg_total_uncert\"].values()).tolist()[delimiter:]\n",
    "        back_sigma.extend((bkg_run3[\"bkg_total_uncert\"].values()).tolist()[delimiter:])\n",
    "\n",
    "    if alpha == 1.0:\n",
    "        scaling_a1 = (1./pow(0.1,3))\n",
    "    else:\n",
    "        scaling_a1 = 1. \n",
    "\n",
    "    for mass in masses:\n",
    "\n",
    "        print(\"Processing mass: \" + mass)\n",
    "        print(\"Signal events run1: {nevts:.5f}\".format( nevts= np.sum(signal_run1[\"signal_\"+ mass].values()*scaling_a1)))\n",
    "        print(\"Signal events run3: {nevts:.5f}\".format( nevts= np.sum(signal_run3[\"signal_\"+ mass].values()*scaling_a1)))\n",
    "\n",
    "        total_sig = np.sum(signal_run1[\"signal_\"+mass].values()*scaling_a1) + np.sum(signal_run3[\"signal_\"+mass].values()*scaling_a1)\n",
    "        total_sig_run1 = np.sum(signal_run1[\"signal_\"+mass].values()*scaling_a1)\n",
    "        total_sig_run3 =  np.sum(signal_run3[\"signal_\"+mass].values()*scaling_a1)\n",
    "        \n",
    "        factor = scaling*(((total_run1/total_sig_run1)+ (total_run3/total_sig_run3))/2.)\n",
    "        \n",
    "        factor = 1.0 \n",
    "        total_sig_adjusted = np.sum(signal_run1[\"signal_\"+mass].values()*scaling_a1*factor) + np.sum(signal_run3[\"signal_\"+mass].values()*scaling_a1*factor)\n",
    "        \n",
    "        scaling_list.append(factor)\n",
    "        \n",
    "\n",
    "        print(\"Scaling factor: \", factor)\n",
    "\n",
    "\n",
    "        # Factor scalings is introduced to have a signal strength between 0 and 10\n",
    "        # We correct by the fraction of events outside the beam window\n",
    "        n_sig_run1 = (signal_run1[\"signal_\"+mass].values()*scaling_a1*fraction_outside*factor).tolist()[delimiter:]\n",
    "        n_sig_run3 = (signal_run3[\"signal_\"+mass].values()*scaling_a1*fraction_outside*factor).tolist()[delimiter:]\n",
    "        n_sig_run1.extend(n_sig_run3)\n",
    "\n",
    "\n",
    "        # Total signal errors are in %, need to convert them to absolute errors for shapesys modifier \n",
    "        # We correct by the fraction of events outside the beam window\n",
    "        sigma_sig_run1 = (signal_run1[\"signal_total_error_\"+mass].values()/100.)*(signal_run1[\"signal_\"+mass].values()*scaling_a1*fraction_outside*factor)\n",
    "        sigma_sig_run3 = (signal_run3[\"signal_total_error_\"+mass].values()/100.)*(signal_run3[\"signal_\"+mass].values()*scaling_a1*fraction_outside*factor)\n",
    "\n",
    "\n",
    "        sigma_sig_run1 = (sigma_sig_run1).tolist()[delimiter:]\n",
    "        sigma_sig_run3 = (sigma_sig_run3).tolist()[delimiter:]\n",
    "        sigma_sig_run1.extend(sigma_sig_run3)\n",
    "\n",
    "\n",
    "\n",
    "        model = pyhf.Model(\n",
    "            {\n",
    "          \"channels\": [\n",
    "            {\n",
    "              \"name\": \"singlechannel\",\n",
    "              \"samples\": [\n",
    "                {\n",
    "                  \"name\": \"signal\",\n",
    "                  \"data\": n_sig_run1,\n",
    "                  \"modifiers\": [\n",
    "                    {\"name\": \"mu\", \"type\": \"normfactor\", \"data\": None}, #This is the scaling which is to be calculated\n",
    "                    {\"name\": \"uncorr_siguncrt\", \"type\": \"shapesys\", \"data\": sigma_sig_run1},\n",
    "                    {\"name\": \"pot_correlated\", \"type\": \"normsys\", \"data\": {\"hi\":1. + (pot_uncert), \"lo\": 1. - (pot_uncert)}},\n",
    "                    #{\"name\": \"flux_correlated\", \"type\": \"normsys\", \"data\": {\"hi\":1. + flux_uncert, \"lo\": 1. -  flux_uncert}},\n",
    "                  ]\n",
    "                },\n",
    "                {\n",
    "                  \"name\": \"background\",\n",
    "                  \"data\": n_back,\n",
    "                  \"modifiers\": [\n",
    "                    {\"name\": \"uncorr_bkguncrt\", \"type\": \"shapesys\", \"data\": back_sigma},\n",
    "                    {\"name\": \"pot_correlated\", \"type\": \"normsys\", \"data\": {\"hi\":1. + pot_uncert, \"lo\": 1 - pot_uncert}},\n",
    "                  ]\n",
    "                }\n",
    "              ]\n",
    "            }\n",
    "          ]\n",
    "        }\n",
    "        )\n",
    "\n",
    "        obs = n_data + model.config.auxdata\n",
    "\n",
    "        poi_values = np.linspace(0., 10., 100)\n",
    "        obs_limit, exp_limits, (scan, results) = pyhf.infer.intervals.upperlimit(\n",
    "            obs, model, poi_values, level=0.1, return_results=True)\n",
    "        \n",
    "        \n",
    "                \n",
    "        CLs_value, p_values, CLs_band = pyhf.infer.hypotest(obs_limit, obs, model, \n",
    "                                                           return_expected_set=True, \n",
    "                                                           return_tail_probs=True)\n",
    "        \n",
    "        print(f\"Upper limit (obs):  = {obs_limit:.4f}\")\n",
    "        print(f\"Upper limit (exp):  = {exp_limits[2]:.4f}\")\n",
    "        print(f\"p-value: = {p_values[1]:.2f}\")\n",
    "\n",
    "        obs_epsilon = (nominal_eps**2)*np.sqrt(obs_limit*factor)\n",
    "        exp_epsilon = (nominal_eps**2)*np.sqrt(exp_limits[2]*factor)\n",
    "        exp_two_down = (nominal_eps**2)*np.sqrt(exp_limits[0]*factor)\n",
    "        exp_one_down = (nominal_eps**2)*np.sqrt(exp_limits[1]*factor)\n",
    "        exp_one_up = (nominal_eps**2)*np.sqrt(exp_limits[3]*factor)\n",
    "        exp_two_up = (nominal_eps**2)*np.sqrt(exp_limits[4]*factor)\n",
    "\n",
    "        obs_eps.append(obs_epsilon)\n",
    "        exp_eps.append(exp_epsilon)\n",
    "        exp_minus_two.append(exp_two_down)\n",
    "        exp_minus_one.append(exp_one_down)\n",
    "        exp_plus_one.append(exp_one_up)\n",
    "        exp_plus_two.append(exp_two_up)\n",
    "        CLb_values.append(p_values[1])\n",
    "        print(f\"Upper limit (obs): epsilon2 = {obs_epsilon}\")\n",
    "        print(f\"Upper limit (exp): epsilon2 = {exp_epsilon}\")\n",
    "        print(f\"Upper limit +2sigma: epsilon2 = {exp_two_up}\")\n",
    "        print(f\"Upper limit +1sigma: epsilon2 = {exp_one_up}\")\n",
    "        print(f\"Upper limit -1sigma: epsilon2 = {exp_one_down}\")\n",
    "        print(f\"Upper limit -2sigma: epsilon2 = {exp_two_down}\")\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5eb0d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if(not tests):\n",
    "\n",
    "\n",
    "    import pandas as pd\n",
    "    from matplotlib import patheffects\n",
    "\n",
    "    limits_dir = \"/home/lmlepin/Desktop/dm_sets/dark_tridents_analysis/\"\n",
    "    plots_dir = \"/home/lmlepin/Desktop/Plots_DT_Drive/2023/sensitivity_plots/\"\n",
    "    sensitivity_files = \"/home/lmlepin/Desktop/dm_sets/dark_tridents_analysis/sensitivity_files/\"\n",
    "\n",
    "    df = pd.read_csv(limits_dir + \"dark_tridents_current_limits.csv\")\n",
    "    df_b = pd.read_csv(limits_dir + \"dark_tridents_current_limits_1.csv\")\n",
    "    df_babar = pd.read_csv(limits_dir + \"babar_paper.csv\")\n",
    "    df_na = pd.read_csv(limits_dir + \"NA48_2.csv\")\n",
    "\n",
    "\n",
    "    if(ratio==\"0.6\"):\n",
    "        dp_masses = [0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1, 0.2, 0.3, 0.4]\n",
    "    else:\n",
    "        dp_masses = [0.010, 0.020, 0.030, \n",
    "              0.040, 0.050, 0.060, \n",
    "              0.065, 0.070, 0.075, \n",
    "              0.080, 0.085, 0.090, \n",
    "              0.095, 0.100, 0.105, \n",
    "              0.110, 0.115, 0.120, 0.125]\n",
    "\n",
    "    plt.figure(figsize=(17,14),dpi=300)\n",
    "    plt.axis([ 1e-2, 1, 1e-11, 1e-5])\n",
    "    plt.plot(dp_masses,exp_eps,label=r'MicroBooNE',color='red')\n",
    "    plt.plot(dp_masses,obs_eps,label=r'MicroBooNE',color='black')\n",
    "\n",
    "\n",
    "\n",
    "    if(dm_type == 'fermion' and alpha == 0.1):\n",
    "        plt.plot(df['X_LSND'],df['Y_LSND'],'-', label=r'LSND',color='green')\n",
    "        plt.fill_between(df['X_LSND'],df['Y_LSND'], 1e-5,color='green',alpha=0.2)\n",
    "        plt.plot(df['X_PLANCK'],df['Y_PLANCK'],'-',color='orange', path_effects=[patheffects.withTickedStroke(spacing=10, angle=280)])\n",
    "        plt.plot(df['X_PLANCK'],df['Y_PLANCK'],'-', label=r'Planck (fermionic DM)',color='orange')\n",
    "    elif(dm_type == 'fermion' and alpha == 1.):\n",
    "        plt.plot(df_b['X_LSND'],df_b['Y_LSND'],'-', label=r'LSND',color='green')\n",
    "        plt.fill_between(df_b['X_LSND'],df_b['Y_LSND'], 1e-5,color='green',alpha=0.2)\n",
    "        plt.plot(df_b['X_PLANCK'],df_b['Y_PLANCK'],'-',color='orange', path_effects=[patheffects.withTickedStroke(spacing=10, angle=280)])\n",
    "        plt.plot(df_b['X_PLANCK'],df_b['Y_PLANCK'],'-', label=r'Planck (fermionic DM)',color='orange')\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "\n",
    "    limit_dict = {'mass':dp_masses,'observed':obs_eps, 'epsilon_squared':exp_eps, 'two_sig_down':exp_minus_two,\n",
    "                 'one_sig_down':exp_minus_one, 'one_sig_up':exp_plus_one, 'two_sig_up':exp_plus_two,\n",
    "                 'CLb':CLb_values}\n",
    "    #df_out = pd.DataFrame.from_dict(limit_dict)\n",
    "   # df_out.to_csv(sensitivity_files + dm_type + \"_\" + tag + \"_sensitivity_alpha_\" + str(alpha) + \"_ratio_\" + ratio + \"_all_runs_full_uncert_signal_flux_0_percent.csv\")\n",
    "\n",
    "\n",
    "    #plt.plot(df['X_BD'],df['Y_BD'],'-', label=r'Beam Dump',color='mediumpurple')\n",
    "    plt.fill_between(df['X_BD'],df['Y_BD'],1e-11,color='mediumpurple',alpha=0.3)\n",
    "    #plt.plot(df_babar['X_babar'],np.square(df_babar['Y_babar']),'-', label=r'BaBar',color='blue')\n",
    "    plt.fill_between(df_babar['X_babar'],np.square(df_babar['Y_babar']), 1e-5,color='blue',alpha=0.2)\n",
    "    #plt.plot(df_na['X']*1e-3,df_na['Y'],'-', label=r'NA48/2',color='blue')\n",
    "    plt.fill_between(df_na['X']*1e-3,df_na['Y'], 1e-5,color='blue',alpha=0.3)\n",
    "    plt.yscale('log')\n",
    "    plt.xscale('log')\n",
    "    plt.ylim(1e-11,1e-5)\n",
    "    plt.xlim(1e-2,5e-1)\n",
    "    plt.legend(fontsize=20,loc=\"lower right\",shadow=True)\n",
    "    plt.xticks(size=25)\n",
    "    plt.yticks(size=25)\n",
    "    plt.title(\"Sensitivity for 7.56e20 POT           \" + dm_type + \" DM: \" + r'$\\alpha_{D}$ = ' + str(alpha), size = 30, pad=20)\n",
    "    plt.xlabel(r'$M_{A^{\\prime}}$[GeV]',size=30, labelpad=20)\n",
    "    plt.ylabel(r'$\\epsilon^2$',size=30, labelpad=20)\n",
    "    #plt.minorticks_off()\n",
    "    #plt.savefig(plots_dir + dm_type + \"_\" + tag + \"_sensitivity_alpha_\" + str(alpha) + \".png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25bfe8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparison with toy-based calculator \n",
    "\n",
    "\n",
    "if(tests):\n",
    "    masses = [\"0.05\"]\n",
    "    delimiter=0\n",
    "    pot_uncert = 0.02 # 2% POT uncertainty \n",
    "\n",
    "\n",
    "    total_bkg = np.sum(bkg_run1[\"bkg_total_hist\"].values()) + np.sum(bkg_run3[\"bkg_total_hist\"].values())\n",
    "\n",
    "    total_run1 = np.sum(bkg_run1[\"bkg_total_hist\"].values())\n",
    "    total_run3 = np.sum(bkg_run3[\"bkg_total_hist\"].values())\n",
    "\n",
    "    n_back = bkg_run1[\"bkg_total_hist\"].values().tolist()[delimiter:]\n",
    "    n_back.extend(bkg_run3[\"bkg_total_hist\"].values().tolist()[delimiter:])\n",
    "\n",
    "\n",
    "    n_data = bkg_run1[\"data_hist\"].values().tolist()[delimiter:]\n",
    "    n_data.extend(bkg_run3[\"data_hist\"].values().tolist()[delimiter:])\n",
    "\n",
    "\n",
    "    if(flat_uncertainty):\n",
    "        back_sigma =  (bkg_run1[\"bkg_total_hist\"].values()*uncertainty).tolist()\n",
    "        back_sigma.extend((bkg_run3[\"bkg_total_hist\"].values()*uncertainty).tolist())\n",
    "    else:\n",
    "        back_sigma =  (bkg_run1[\"bkg_total_uncert\"].values()).tolist()[delimiter:]\n",
    "        back_sigma.extend((bkg_run3[\"bkg_total_uncert\"].values()).tolist()[delimiter:])\n",
    "\n",
    "    if alpha == 1.0:\n",
    "        scaling_a1 = (1./pow(0.1,3))\n",
    "    else:\n",
    "        scaling_a1 = 1. \n",
    "\n",
    "    for mass in masses:\n",
    "\n",
    "        print(\"Processing mass: \" + mass)\n",
    "        print(\"Signal events run1: {nevts:.5f}\".format( nevts= np.sum(signal_run1[\"signal_\"+ mass].values()*scaling_a1)))\n",
    "        print(\"Signal events run3: {nevts:.5f}\".format( nevts= np.sum(signal_run3[\"signal_\"+ mass].values()*scaling_a1)))\n",
    "\n",
    "        total_sig = np.sum(signal_run1[\"signal_\"+mass].values()*scaling_a1) + np.sum(signal_run3[\"signal_\"+mass].values()*scaling_a1)\n",
    "        total_sig_run1 = np.sum(signal_run1[\"signal_\"+mass].values()*scaling_a1)\n",
    "        total_sig_run3 =  np.sum(signal_run3[\"signal_\"+mass].values()*scaling_a1)\n",
    "        factor = scaling*(((total_run1/total_sig_run1)+ (total_run3/total_sig_run3))/2.)\n",
    "        total_sig_adjusted = np.sum(signal_run1[\"signal_\"+mass].values()*scaling_a1*factor) + np.sum(signal_run3[\"signal_\"+mass].values()*scaling_a1*factor)\n",
    "        scaling_list.append(factor)\n",
    "\n",
    "        print(\"Scaling factor: \", factor)\n",
    "\n",
    "\n",
    "        # Factor scalings is introduced to have a signal strength between 0 and 10\n",
    "        n_sig_run1 = (signal_run1[\"signal_\"+mass].values()*scaling_a1*factor).tolist()[delimiter:]\n",
    "        n_sig_run3 = (signal_run3[\"signal_\"+mass].values()*scaling_a1*factor).tolist()[delimiter:]\n",
    "        n_sig_run1.extend(n_sig_run3)\n",
    "\n",
    "\n",
    "        # Total signal errors are in %, need to convert them to absolute errors for shapesys modifier  \n",
    "        sigma_sig_run1 = (signal_run1[\"signal_total_error_\"+mass].values()/100.)*(signal_run1[\"signal_\"+mass].values()*scaling_a1*factor)\n",
    "        sigma_sig_run3 = (signal_run3[\"signal_total_error_\"+mass].values()/100.)*(signal_run3[\"signal_\"+mass].values()*scaling_a1*factor)\n",
    "\n",
    "\n",
    "        sigma_sig_run1 = (sigma_sig_run1).tolist()[delimiter:]\n",
    "        sigma_sig_run3 = (sigma_sig_run3).tolist()[delimiter:]\n",
    "        sigma_sig_run1.extend(sigma_sig_run3)\n",
    "\n",
    "\n",
    "\n",
    "        model = pyhf.Model(\n",
    "            {\n",
    "          \"channels\": [\n",
    "            {\n",
    "              \"name\": \"singlechannel\",\n",
    "              \"samples\": [\n",
    "                {\n",
    "                  \"name\": \"signal\",\n",
    "                  \"data\": n_sig_run1,\n",
    "                  \"modifiers\": [\n",
    "                    {\"name\": \"mu\", \"type\": \"normfactor\", \"data\": None}, #This is the scaling which is to be calculated\n",
    "                    {\"name\": \"uncorr_siguncrt\", \"type\": \"shapesys\", \"data\": sigma_sig_run1},\n",
    "                    {\"name\": \"pot_correlaated\", \"type\": \"normsys\", \"data\": {\"hi\":1.02, \"lo\":0.98}},\n",
    "                  ]\n",
    "                },\n",
    "                {\n",
    "                  \"name\": \"background\",\n",
    "                  \"data\": n_back,\n",
    "                  \"modifiers\": [\n",
    "                    {\"name\": \"uncorr_bkguncrt\", \"type\": \"shapesys\", \"data\": back_sigma},\n",
    "                    {\"name\": \"pot_correlated\", \"type\": \"normsys\", \"data\": {\"hi\":1.02, \"lo\":0.98}},\n",
    "                  ]\n",
    "                }\n",
    "              ]\n",
    "            }\n",
    "          ]\n",
    "        }\n",
    "        )\n",
    "\n",
    "        obs = n_data + model.config.auxdata\n",
    "\n",
    "        poi_values = np.linspace(0., 10., 100)\n",
    "        obs_limit, exp_limits, (scan, results) = pyhf.infer.intervals.upperlimit(\n",
    "            obs, model, poi_values, level=0.1, return_results=True)\n",
    "        \n",
    "        \n",
    "        print(\"Printing upper limits results...\")\n",
    "        print(f\"Upper limit (obs):  = {obs_limit:.4f}\")\n",
    "        print(f\"Upper limit (exp):  = {exp_limits[2]:.4f}\")\n",
    "\n",
    "        obs_epsilon = (nominal_eps**2)*np.sqrt(obs_limit*factor)\n",
    "        exp_epsilon = (nominal_eps**2)*np.sqrt(exp_limits[2]*factor)\n",
    "        exp_two_down = (nominal_eps**2)*np.sqrt(exp_limits[0]*factor)\n",
    "        exp_one_down = (nominal_eps**2)*np.sqrt(exp_limits[1]*factor)\n",
    "        exp_one_up = (nominal_eps**2)*np.sqrt(exp_limits[3]*factor)\n",
    "        exp_two_up = (nominal_eps**2)*np.sqrt(exp_limits[4]*factor)\n",
    "\n",
    "        print(f\"Upper limit (obs): epsilon2 = {obs_epsilon}\")\n",
    "        print(f\"Upper limit (exp): epsilon2 = {exp_epsilon}\")\n",
    "        print(f\"Upper limit +2sigma: epsilon2 = {exp_two_up}\")\n",
    "        print(f\"Upper limit +1sigma: epsilon2 = {exp_one_up}\")\n",
    "        print(f\"Upper limit -1sigma: epsilon2 = {exp_one_down}\")\n",
    "        print(f\"Upper limit -2sigma: epsilon2 = {exp_two_down}\")\n",
    "        print(\"\\n\")\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "        '''\n",
    "        print(\"Printing CLs values for the observed value of mu (Asymptotic)...\")\n",
    "        CLs_obs_asymp, CLs_exp_asymp = pyhf.infer.hypotest(exp_limits[2], obs, model, \n",
    "                                                           return_expected_set=True)\n",
    "        \n",
    "        print(f\"Observed CLs = {CLs_obs_asymp}\")\n",
    "        print(f\"Expected CLs = {CLs_exp_asymp}\")\n",
    "        print(\"\\n\")\n",
    "        '''\n",
    "        \n",
    "        print(\"Printing CLs values for the observed value of mu (Toys)...\")\n",
    "        CLs_obs_toys, CLs_exp_toys, p_values = pyhf.infer.hypotest(exp_limits[2], obs, model, \n",
    "                                                           return_expected_set=True, \n",
    "                                                           return_tail_probs=True)\n",
    "        print(f\"Observed CLs = {CLs_obs_toys}\")\n",
    "        print(f\"Expected CLs = {CLs_exp_toys}\")\n",
    "        print(f\"P-values = {p_values}\")\n",
    "        print(\"\\n\")\n",
    "        \n",
    "       # print(f\"Ratio of both calculators = {CLs_obs_toys/CLs_obs_asymp}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
